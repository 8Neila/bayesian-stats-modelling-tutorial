{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import janitor as jn\n",
    "import pymc3 as pm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darwin's Finches\n",
    "\n",
    "A research group has taken measurements of the descendants of the finches that Charles Darwin observed when he postulated the theory of evolution.\n",
    "\n",
    "We will be using Bayesian methods to analyze this data, specifically answering the question of how quantitatively different two species of birds' beaks are.\n",
    "\n",
    "## Data Credits\n",
    "\n",
    "The Darwin's finches datasets come from the paper, [40 years of evolution. Darwin's finches on Daphne Major Island][data]. \n",
    "\n",
    "One row of data has been added for pedagogical purposes.\n",
    "\n",
    "[data]: (https://datadryad.org/resource/doi:10.5061/dryad.g6g3h). \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Load the data. It is located at `../data/finch_beaks_2012.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../data/finch_beaks_2012.csv')\n",
    "\n",
    "# Data cleaning methods. This is provided for you. Follow along the annotations\n",
    "# to learn what's going on.\n",
    "df = (jn.DataFrame(df)  # wrap dataframe in a Janitor dataframe.\n",
    "      .clean_names()    # clean column names\n",
    "      .rename_column('blenth', 'beak_length')  # rename blength to beak_length (readability fix)\n",
    "      .rename_column('bdepth', 'beak_depth')   # rename bdepth to beak_depth (readability fix)\n",
    "      .label_encode('species')  # create a `species_enc` column that has the species encoded numerically\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have added one row of data, simulating the discovery of an \"unknown\" species of finch for which beak measurements have been taken.\n",
    "\n",
    "For pedagogical brevity, we will analyze only beak depth during the class. However, I would encourage you to perform a similar analysis for beak length as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortis_filter = df['species'] == 'fortis'\n",
    "scandens_filter = df['species'] == 'scandens'\n",
    "unknown_filter = df['species'] == 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as beak_depth_model:\n",
    "    # Beaks cannot be of \"negative\" mean, therefore, HalfNormal is \n",
    "    # a reasonable, constrained prior.\n",
    "    mean = pm.HalfNormal('mean', sd=100, shape=(3,))\n",
    "    # Define the prior for the observed variance of the beak depths\n",
    "    sd = pm.HalfCauchy('sd', beta=100, shape=(3,))\n",
    "    # Define the nuisance parameter nu for the T distribution\n",
    "    nu = pm.Exponential('nu', lam=1/29.) + 1\n",
    "    \n",
    "    # Define the likelihood.\n",
    "    like = pm.StudentT('likelihood', \n",
    "                       nu=nu,\n",
    "                       mu=mean[df['species_enc']], \n",
    "                       sd=sd[df['species_enc']], \n",
    "                       observed=df['beak_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Perform MCMC sampling to estimate the posterior distribution of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beak_depth_model:\n",
    "    trace = pm.sample(2000, tuning=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Diagnose whether the sampling has converged or not using trace plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Visualize the posterior distribution over the parameters using the forest plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Visualize the posterior distribution of the means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exericse\n",
    "\n",
    "Perform a posterior predictive check to visually diagnose whether the model describes the data generating process well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pm.sample_ppc(trace, model=beak_depth_model, samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def ecdf(data):\n",
    "    x, y = np.sort(data), np.arange(1, len(data)+1) / len(data)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Each column in the samples (key: \"likelihood\") corresponds to simulated measurements of each finch in the dataset. We can use fancy indexing along the columns (axis 1) to select out simulated measurements for each category, and then flatten the resultant array to get the full estimated distribution of values for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[scandens_filter]['species_enc'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_fortis = fig.add_subplot(2, 1, 1)\n",
    "ax_scandens = fig.add_subplot(2, 1, 2, sharex=ax_fortis)\n",
    "\n",
    "x_s, y_s = ecdf(samples['likelihood'][:, df[fortis_filter].index].flatten())\n",
    "ax_fortis.plot(x_s, y_s, label='samples')\n",
    "x, y = ecdf(df[fortis_filter]['beak_depth'])\n",
    "ax_fortis.plot(x, y, label='data')\n",
    "ax_fortis.legend()\n",
    "ax_fortis.set_title('fortis')\n",
    "\n",
    "x_s, y_s = ecdf(samples['likelihood'][:, df[scandens_filter].index].flatten())\n",
    "ax_scandens.plot(x_s, y_s, label='samples')\n",
    "x, y = ecdf(df[scandens_filter]['beak_depth'])\n",
    "ax_scandens.plot(x, y, label='data')\n",
    "ax_scandens.legend()\n",
    "ax_scandens.set_title('scandens')\n",
    "ax_scandens.set_xlabel('beak length')\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- Is the posterior distribution for the unknown species reasonable, given what you might know about finch beaks?\n",
    "- How quantitatively different are beak lengths between the fortis and scandens finch species?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. NumPy-like fancy indexing lets us write models in a concise fashion.\n",
    "1. Posterior estimates can show up as being \"unreasonable\", \"absurd\", or at the minimum, counter-intuitive, if we do not impose the right set of assumptions on the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
